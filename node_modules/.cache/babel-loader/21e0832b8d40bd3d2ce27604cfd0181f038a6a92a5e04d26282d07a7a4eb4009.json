{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AbstractTokenizer = void 0;\nconst peek_readable_1 = require(\"peek-readable\");\n/**\r\n * Core tokenizer\r\n */\nclass AbstractTokenizer {\n  constructor(fileInfo) {\n    /**\r\n     * Tokenizer-stream position\r\n     */\n    this.position = 0;\n    this.numBuffer = new Uint8Array(8);\n    this.fileInfo = fileInfo ? fileInfo : {};\n  }\n  /**\r\n   * Read a token from the tokenizer-stream\r\n   * @param token - The token to read\r\n   * @param position - If provided, the desired position in the tokenizer-stream\r\n   * @returns Promise with token data\r\n   */\n  async readToken(token, position = this.position) {\n    const uint8Array = Buffer.alloc(token.len);\n    const len = await this.readBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Peek a token from the tokenizer-stream.\r\n   * @param token - Token to peek from the tokenizer-stream.\r\n   * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n   * @returns Promise with token data\r\n   */\n  async peekToken(token, position = this.position) {\n    const uint8Array = Buffer.alloc(token.len);\n    const len = await this.peekBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n  async readNumber(token) {\n    const len = await this.readBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n  async peekNumber(token) {\n    const len = await this.peekBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n   * @param length - Number of bytes to ignore\r\n   * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n   */\n  async ignore(length) {\n    if (this.fileInfo.size !== undefined) {\n      const bytesLeft = this.fileInfo.size - this.position;\n      if (length > bytesLeft) {\n        this.position += bytesLeft;\n        return bytesLeft;\n      }\n    }\n    this.position += length;\n    return length;\n  }\n  async close() {\n    // empty\n  }\n  normalizeOptions(uint8Array, options) {\n    if (options && options.position !== undefined && options.position < this.position) {\n      throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n    }\n    if (options) {\n      return {\n        mayBeLess: options.mayBeLess === true,\n        offset: options.offset ? options.offset : 0,\n        length: options.length ? options.length : uint8Array.length - (options.offset ? options.offset : 0),\n        position: options.position ? options.position : this.position\n      };\n    }\n    return {\n      mayBeLess: false,\n      offset: 0,\n      length: uint8Array.length,\n      position: this.position\n    };\n  }\n}\nexports.AbstractTokenizer = AbstractTokenizer;","map":{"version":3,"names":["Object","defineProperty","exports","value","AbstractTokenizer","peek_readable_1","require","constructor","fileInfo","position","numBuffer","Uint8Array","readToken","token","uint8Array","Buffer","alloc","len","readBuffer","EndOfStreamError","get","peekToken","peekBuffer","readNumber","length","peekNumber","ignore","size","undefined","bytesLeft","close","normalizeOptions","options","Error","mayBeLess","offset"],"sources":["/Users/nidhi/Desktop/cve-analysis-app/node_modules/strtok3/lib/AbstractTokenizer.js"],"sourcesContent":["\"use strict\";\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.AbstractTokenizer = void 0;\r\nconst peek_readable_1 = require(\"peek-readable\");\r\n/**\r\n * Core tokenizer\r\n */\r\nclass AbstractTokenizer {\r\n    constructor(fileInfo) {\r\n        /**\r\n         * Tokenizer-stream position\r\n         */\r\n        this.position = 0;\r\n        this.numBuffer = new Uint8Array(8);\r\n        this.fileInfo = fileInfo ? fileInfo : {};\r\n    }\r\n    /**\r\n     * Read a token from the tokenizer-stream\r\n     * @param token - The token to read\r\n     * @param position - If provided, the desired position in the tokenizer-stream\r\n     * @returns Promise with token data\r\n     */\r\n    async readToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.readBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Peek a token from the tokenizer-stream.\r\n     * @param token - Token to peek from the tokenizer-stream.\r\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n     * @returns Promise with token data\r\n     */\r\n    async peekToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.peekBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async readNumber(token) {\r\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async peekNumber(token) {\r\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n     * @param length - Number of bytes to ignore\r\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n     */\r\n    async ignore(length) {\r\n        if (this.fileInfo.size !== undefined) {\r\n            const bytesLeft = this.fileInfo.size - this.position;\r\n            if (length > bytesLeft) {\r\n                this.position += bytesLeft;\r\n                return bytesLeft;\r\n            }\r\n        }\r\n        this.position += length;\r\n        return length;\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n    normalizeOptions(uint8Array, options) {\r\n        if (options && options.position !== undefined && options.position < this.position) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        if (options) {\r\n            return {\r\n                mayBeLess: options.mayBeLess === true,\r\n                offset: options.offset ? options.offset : 0,\r\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\r\n                position: options.position ? options.position : this.position\r\n            };\r\n        }\r\n        return {\r\n            mayBeLess: false,\r\n            offset: 0,\r\n            length: uint8Array.length,\r\n            position: this.position\r\n        };\r\n    }\r\n}\r\nexports.AbstractTokenizer = AbstractTokenizer;\r\n"],"mappings":"AAAA,YAAY;;AACZA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,iBAAiB,GAAG,KAAK,CAAC;AAClC,MAAMC,eAAe,GAAGC,OAAO,CAAC,eAAe,CAAC;AAChD;AACA;AACA;AACA,MAAMF,iBAAiB,CAAC;EACpBG,WAAWA,CAACC,QAAQ,EAAE;IAClB;AACR;AACA;IACQ,IAAI,CAACC,QAAQ,GAAG,CAAC;IACjB,IAAI,CAACC,SAAS,GAAG,IAAIC,UAAU,CAAC,CAAC,CAAC;IAClC,IAAI,CAACH,QAAQ,GAAGA,QAAQ,GAAGA,QAAQ,GAAG,CAAC,CAAC;EAC5C;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMI,SAASA,CAACC,KAAK,EAAEJ,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;IAC7C,MAAMK,UAAU,GAAGC,MAAM,CAACC,KAAK,CAACH,KAAK,CAACI,GAAG,CAAC;IAC1C,MAAMA,GAAG,GAAG,MAAM,IAAI,CAACC,UAAU,CAACJ,UAAU,EAAE;MAAEL;IAAS,CAAC,CAAC;IAC3D,IAAIQ,GAAG,GAAGJ,KAAK,CAACI,GAAG,EACf,MAAM,IAAIZ,eAAe,CAACc,gBAAgB,CAAC,CAAC;IAChD,OAAON,KAAK,CAACO,GAAG,CAACN,UAAU,EAAE,CAAC,CAAC;EACnC;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAMO,SAASA,CAACR,KAAK,EAAEJ,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;IAC7C,MAAMK,UAAU,GAAGC,MAAM,CAACC,KAAK,CAACH,KAAK,CAACI,GAAG,CAAC;IAC1C,MAAMA,GAAG,GAAG,MAAM,IAAI,CAACK,UAAU,CAACR,UAAU,EAAE;MAAEL;IAAS,CAAC,CAAC;IAC3D,IAAIQ,GAAG,GAAGJ,KAAK,CAACI,GAAG,EACf,MAAM,IAAIZ,eAAe,CAACc,gBAAgB,CAAC,CAAC;IAChD,OAAON,KAAK,CAACO,GAAG,CAACN,UAAU,EAAE,CAAC,CAAC;EACnC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMS,UAAUA,CAACV,KAAK,EAAE;IACpB,MAAMI,GAAG,GAAG,MAAM,IAAI,CAACC,UAAU,CAAC,IAAI,CAACR,SAAS,EAAE;MAAEc,MAAM,EAAEX,KAAK,CAACI;IAAI,CAAC,CAAC;IACxE,IAAIA,GAAG,GAAGJ,KAAK,CAACI,GAAG,EACf,MAAM,IAAIZ,eAAe,CAACc,gBAAgB,CAAC,CAAC;IAChD,OAAON,KAAK,CAACO,GAAG,CAAC,IAAI,CAACV,SAAS,EAAE,CAAC,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMe,UAAUA,CAACZ,KAAK,EAAE;IACpB,MAAMI,GAAG,GAAG,MAAM,IAAI,CAACK,UAAU,CAAC,IAAI,CAACZ,SAAS,EAAE;MAAEc,MAAM,EAAEX,KAAK,CAACI;IAAI,CAAC,CAAC;IACxE,IAAIA,GAAG,GAAGJ,KAAK,CAACI,GAAG,EACf,MAAM,IAAIZ,eAAe,CAACc,gBAAgB,CAAC,CAAC;IAChD,OAAON,KAAK,CAACO,GAAG,CAAC,IAAI,CAACV,SAAS,EAAE,CAAC,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMgB,MAAMA,CAACF,MAAM,EAAE;IACjB,IAAI,IAAI,CAAChB,QAAQ,CAACmB,IAAI,KAAKC,SAAS,EAAE;MAClC,MAAMC,SAAS,GAAG,IAAI,CAACrB,QAAQ,CAACmB,IAAI,GAAG,IAAI,CAAClB,QAAQ;MACpD,IAAIe,MAAM,GAAGK,SAAS,EAAE;QACpB,IAAI,CAACpB,QAAQ,IAAIoB,SAAS;QAC1B,OAAOA,SAAS;MACpB;IACJ;IACA,IAAI,CAACpB,QAAQ,IAAIe,MAAM;IACvB,OAAOA,MAAM;EACjB;EACA,MAAMM,KAAKA,CAAA,EAAG;IACV;EAAA;EAEJC,gBAAgBA,CAACjB,UAAU,EAAEkB,OAAO,EAAE;IAClC,IAAIA,OAAO,IAAIA,OAAO,CAACvB,QAAQ,KAAKmB,SAAS,IAAII,OAAO,CAACvB,QAAQ,GAAG,IAAI,CAACA,QAAQ,EAAE;MAC/E,MAAM,IAAIwB,KAAK,CAAC,uEAAuE,CAAC;IAC5F;IACA,IAAID,OAAO,EAAE;MACT,OAAO;QACHE,SAAS,EAAEF,OAAO,CAACE,SAAS,KAAK,IAAI;QACrCC,MAAM,EAAEH,OAAO,CAACG,MAAM,GAAGH,OAAO,CAACG,MAAM,GAAG,CAAC;QAC3CX,MAAM,EAAEQ,OAAO,CAACR,MAAM,GAAGQ,OAAO,CAACR,MAAM,GAAIV,UAAU,CAACU,MAAM,IAAIQ,OAAO,CAACG,MAAM,GAAGH,OAAO,CAACG,MAAM,GAAG,CAAC,CAAE;QACrG1B,QAAQ,EAAEuB,OAAO,CAACvB,QAAQ,GAAGuB,OAAO,CAACvB,QAAQ,GAAG,IAAI,CAACA;MACzD,CAAC;IACL;IACA,OAAO;MACHyB,SAAS,EAAE,KAAK;MAChBC,MAAM,EAAE,CAAC;MACTX,MAAM,EAAEV,UAAU,CAACU,MAAM;MACzBf,QAAQ,EAAE,IAAI,CAACA;IACnB,CAAC;EACL;AACJ;AACAP,OAAO,CAACE,iBAAiB,GAAGA,iBAAiB","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}